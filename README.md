# Lifelong-Learning

## Survey
* Class-incremental learning: survey and performance evaluation (arXiv 2020) [[_paper_](https://arxiv.org/abs/2010.15277)]
* A Comprehensive Study of Class Incremental Learning Algorithms for Visual Tasks (arXiv 2020) [[_paper_](https://arxiv.org/pdf/2011.01844.pdf)]
* Continual learning: A comparative study on how to defy forgetting in classification tasks (arXiv 2019) [[_paper_](https://arxiv.org/pdf/1909.08383.pdf)]
* Continual Lifelong Learning with Neural Networks: A Review (Neural Networks) [[_paper_](https://arxiv.org/abs/1802.07569)]

## Papers
### 2020
* Meta-Consolidation for Continual Learning (__NeurIPS2020__) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Understanding the Role of Training Regimes in Continual Learning (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Continual Learning with Node-Importance based Adaptive Group Sparse Regularization (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Coresets via Bilevel Optimization for Continual Learning and Streaming (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Continual Deep Learning by Functional Regularisation of Memorable Past (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Dark Experience for General Continual Learning: a Strong, Simple Baseline (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [[code]()]
* GAN Memory with No Forgetting (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Calibrating CNNs for Lifelong Learning (NeurIPS2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Initial Classifier Weights Replay for Memoryless Class Incremental Learning (BMVC2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Adversarial Continual Learning (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
* REMIND Your Neural Network to Prevent Catastrophic Forgetting (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
* Incremental Meta-Learning via Indirect Discriminant Alignment (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
* Memory-Efficient Incremental Learning Through Feature Adaptation (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
PODNet: Pooled Outputs Distillation for Small-Tasks Incremental Learning (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
Reparameterizing Convolutions for Incremental Multi-Task Learning Without Task Interference (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Learning latent representions across multiple data domains using Lifelong VAEGAN (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Online Continual Learning under Extreme Memory Constraints (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Class-Incremental Domain Adaptation (ECCV2020)[[paper](https://arxiv.org/abs/2010.00352?context=cs)]
More Classifiers, Less Forgetting: A Generic Multi-classifier Paradigm for Incremental Learning (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
GDumb: A Simple Approach that Questions Our Progress in Continual Learning (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Imbalanced Continual Learning with Partitioning Reservoir Sampling (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Topology-Preserving Class-Incremental Learning (ECCV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
GraphSAIL: Graph Structure Aware Incremental Learning for Recommender Systems (CIKM2020)[[paper](https://arxiv.org/abs/2010.00352?context=cs)]
OvA-INN: Continual Learning with Invertible Neural Networks (IJCNN2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning (ICLM2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Optimal Continual Learning has Perfect Memory and is NP-HARD (ICML2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Neural Topic Modeling with Continual Lifelong Learning (ICML2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Semantic Drift Compensation for Class-Incremental Learning (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
Few-Shot Class-Incremental Learning (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Modeling the Background for Incremental Learning in Semantic Segmentation (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Incremental Few-Shot Object Detection (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Incremental Learning In Online Scenario (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Maintaining Discrimination and Fairness in Class Incremental Learning (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Conditional Channel Gated Networks for Task-Aware Continual Learning (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Continual Learning with Extended Kronecker-factored Approximate Curvature (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
iTAML : An Incremental Task-Agnostic Meta-learning Approach (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
Mnemonics Training: Multi-Class Incremental Learning without Forgetting (CVPR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]
ScaIL: Classifier Weights Scaling for Class Incremental Learning (WACV2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Accepted papers(ICLR2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)]
Brain-inspired replay for continual learning with artificial neural networks (Natrue Communications 2020) [[paper](https://arxiv.org/abs/2010.00352?context=cs)] [code]

### 2019
Compacting, Picking and Growing for Unforgetting Continual Learning (NeurIPS2019)[paper][code]
Increasingly Packing Multiple Facial-Informatics Modules in A Unified Deep-Learning Model via Lifelong Learning (ICMR2019) [paper][code]
Towards Training Recurrent Neural Networks for Lifelong Learning (Neural Computation 2019) [paper]
IL2M: Class Incremental Learning With Dual Memory (ICCV2019) [paper]
Incremental Learning Using Conditional Adversarial Networks (ICCV2019) [paper]
Adaptive Deep Models for Incremental Learning: Considering Capacity Scalability and Sustainability (KDD2019) [paper]
Random Path Selection for Incremental Learning (NeurIPS2019) [paper]
Online Continual Learning with Maximal Interfered Retrieval (NeurIPS2019) [paper]
Overcoming Catastrophic Forgetting with Unlabeled Data in the Wild (ICCV2019) [paper]
Continual Learning by Asymmetric Loss Approximation with Single-Side Overestimation (ICCV2019) [paper]
Lifelong GAN: Continual Learning for Conditional Image Generation (ICCV2019) [paper]
Continual learning of context-dependent processing in neural networks (Nature Machine Intelligence 2019) [paper] [code]
Large Scale Incremental Learning (CVPR2019) [paper] [code]
Learning a Unified Classifier Incrementally via Rebalancing (CVPR2019) [paper] [code]
Learning Without Memorizing (CVPR2019) [paper]
Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning (CVPR2019) [paper]
Task-Free Continual Learning (CVPR2019) [paper]
Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting (ICML2019) [paper]
Efficient Lifelong Learning with A-GEM (ICLR2019) [paper] [code]
Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference (ICLR2019) [paper] [code]
Overcoming Catastrophic Forgetting via Model Adaptation (ICLR2019) [paper]
A comprehensive, application-oriented study of catastrophic forgetting in DNNs (ICLR2019) [paper]

### 2018
Memory Replay GANs: learning to generate images from new categories without forgetting (NIPS2018) [paper] [code]
Reinforced Continual Learning (NIPS2018) [paper] [code]
Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting (NIPS2018) [paper]
Rotate your Networks: Better Weight Consolidation and Less Catastrophic Forgetting (R-EWC) (ICPR2018) [paper] [code]
Exemplar-Supported Generative Reproduction for Class Incremental Learning (BMVC2018) [paper] [code]
End-to-End Incremental Learning (ECCV2018) [paper][code]
Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence (ECCV2018)[paper]
Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights (ECCV2018) [paper] [code]
Memory Aware Synapses: Learning what (not) to forget (ECCV2018) [paper] [code]
Lifelong Learning via Progressive Distillation and Retrospection (ECCV2018) [paper]
PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning (CVPR2018) [paper] [code]
Overcoming Catastrophic Forgetting with Hard Attention to the Task (ICML2018) [paper] [code]
Lifelong Learning with Dynamically Expandable Networks (ICLR2018) [paper]
FearNet: Brain-Inspired Model for Incremental Learning (ICLR2018) [paper]

### 2017
Incremental Learning of Object Detectors Without Catastrophic Forgetting (ICCV2017) [paper]
Overcoming catastrophic forgetting in neural networks (EWC) (PNAS2017) [paper] [code] [code]
Continual Learning Through Synaptic Intelligence (ICML2017) [paper] [code]
Gradient Episodic Memory for Continual Learning (NIPS2017) [paper] [code]
iCaRL: Incremental Classifier and Representation Learning (CVPR2017) [paper] [code]
Continual Learning with Deep Generative Replay (NIPS2017) [paper] [code]
Overcoming Catastrophic Forgetting by Incremental Moment Matching (NIPS2017) [paper] [code]
Expert Gate: Lifelong Learning with a Network of Experts (CVPR2017) [paper]
Encoder Based Lifelong Learning (ICCV2017) [paper]


## Workshops


## Labs

## Challenge or Competitions
